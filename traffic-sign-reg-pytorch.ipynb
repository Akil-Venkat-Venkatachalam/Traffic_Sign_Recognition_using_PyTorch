{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":657000,"sourceType":"datasetVersion","datasetId":327959}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import necessary Modules","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import random_split\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nimport pickle\nimport numpy as np\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T21:36:08.444564Z","iopub.execute_input":"2025-08-12T21:36:08.444874Z","iopub.status.idle":"2025-08-12T21:36:16.097966Z","shell.execute_reply.started":"2025-08-12T21:36:08.444814Z","shell.execute_reply":"2025-08-12T21:36:16.097328Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# A function to read and load the pickle file","metadata":{}},{"cell_type":"code","source":"\ndef load_pickle(path):\n    with open(path,'rb') as f:\n        return pickle.load(f)\n\ntransform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n\ntrain_ds = load_pickle('/kaggle/input/traffic-signs-preprocessed/train.pickle')\ntest_ds = load_pickle('/kaggle/input/traffic-signs-preprocessed/test.pickle')\n\n\nprint(type(train_ds))\nprint(train_ds.keys())\nprint(train_ds[\"features\"].shape, train_ds[\"labels\"].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T21:36:16.099415Z","iopub.execute_input":"2025-08-12T21:36:16.099800Z","iopub.status.idle":"2025-08-12T21:36:17.770155Z","shell.execute_reply.started":"2025-08-12T21:36:16.099776Z","shell.execute_reply":"2025-08-12T21:36:17.769263Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Custom Module for formatting the data for using it in the dataloader","metadata":{}},{"cell_type":"code","source":"class TrafficDs(Dataset):\n    def __init__(self,features,labels,transform=None):\n        self.features = features\n        self.labels = labels\n        self.transform = transform\n    \n        \n    def __len__(self):\n        return len (self.features)\n\n\n    def __getitem__(self, idx):\n        image = self.features[idx]  \n        label = self.labels[idx]\n    \n        # Fix shape\n        import numpy as np\n        image = np.squeeze(image)  # (32, 32, 3)\n    \n        from PIL import Image\n        image = Image.fromarray(image)\n    \n        if self.transform:\n            image = self.transform(image)\n    \n        return image, label        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T21:36:44.900285Z","iopub.execute_input":"2025-08-12T21:36:44.900580Z","iopub.status.idle":"2025-08-12T21:36:44.906418Z","shell.execute_reply.started":"2025-08-12T21:36:44.900558Z","shell.execute_reply":"2025-08-12T21:36:44.905661Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Creating the datasets","metadata":{}},{"cell_type":"code","source":"train_dataset = TrafficDs(\n    train_ds[\"features\"], train_ds[\"labels\"], transform=transform\n)\ntest_dataset = TrafficDs(\n    test_ds[\"features\"], test_ds[\"labels\"], transform=transform\n)\n\n\nT_ind = int(0.75*len(train_dataset))\nV_ind = int(int(len(train_dataset)) -  T_ind)\ntrain , val =  random_split(train_dataset,[T_ind,V_ind])\n\ntrain_loader = DataLoader(train, batch_size=64, shuffle=True)\nval_loader = DataLoader( val, batch_size=64, shuffle=False)\ntest_loader = DataLoader( test_dataset, batch_size=64, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T21:36:50.044668Z","iopub.execute_input":"2025-08-12T21:36:50.044991Z","iopub.status.idle":"2025-08-12T21:36:50.055008Z","shell.execute_reply.started":"2025-08-12T21:36:50.044966Z","shell.execute_reply":"2025-08-12T21:36:50.054378Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# see the image and label shape","metadata":{}},{"cell_type":"code","source":"images, labels = next(iter(train_loader))\nprint(images.shape, labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T21:36:52.272402Z","iopub.execute_input":"2025-08-12T21:36:52.273035Z","iopub.status.idle":"2025-08-12T21:36:52.313873Z","shell.execute_reply.started":"2025-08-12T21:36:52.273010Z","shell.execute_reply":"2025-08-12T21:36:52.313148Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visulaise the image in the files","metadata":{}},{"cell_type":"code","source":"img = images[10]\nimg = img * 0.5 + 0.5\nimg = img.permute(1, 2, 0).cpu().numpy()\nplt.imshow(img)\nplt.axis('off')  \nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T21:36:55.590047Z","iopub.execute_input":"2025-08-12T21:36:55.590348Z","iopub.status.idle":"2025-08-12T21:36:55.723233Z","shell.execute_reply.started":"2025-08-12T21:36:55.590328Z","shell.execute_reply":"2025-08-12T21:36:55.722464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Custom CNN Network for calssification","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass TrafficNet(nn.Module):\n    def __init__(self):\n        super(TrafficNet, self).__init__()\n        self.cn1 = nn.Conv2d(3,32,3,1)\n        self.cn2 = nn.Conv2d(32,64,3,1)\n        self.fc1 =  nn.Linear(64*6*6,128)\n        self.fc2 = nn.Linear(128,43)\n\n    \n    def forward(self,x):\n        x = F.relu(self.cn1(x))\n        x = F.max_pool2d(x,2)\n        \n        x = F.relu(self.cn2(x))\n        x = F.max_pool2d(x,2)\n\n        x = torch.flatten(x,1)\n        x = F.relu(self.fc1(x))\n        x= self.fc2(x)\n        return x\n        \n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T21:37:00.372720Z","iopub.execute_input":"2025-08-12T21:37:00.373560Z","iopub.status.idle":"2025-08-12T21:37:00.380215Z","shell.execute_reply.started":"2025-08-12T21:37:00.373531Z","shell.execute_reply":"2025-08-12T21:37:00.379344Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training and Validating the Model","metadata":{}},{"cell_type":"code","source":"model = TrafficNet()\nlosses = nn.CrossEntropyLoss()\nopt = torch.optim.Adam(model.parameters(), lr = 0.001)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\nnum_epochs = 15\ntrain_losses = []\nval_losses = []\n\nfor epoch in range(num_epochs):\n    # Training\n    model.train()\n    tot_loss = 0\n    for img, lab in train_loader:\n        img, lab = img.to(device), lab.to(device)\n        opt.zero_grad()\n        out = model(img)\n        loss = losses(out, lab)\n        loss.backward()\n        opt.step()\n        tot_loss += loss.item()\n    avg_train_loss = tot_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for img, lab in val_loader:\n            img, lab = img.to(device), lab.to(device)\n            out = model(img)\n            loss = losses(out, lab)\n            val_loss += loss.item()\n            \n    avg_val_loss = val_loss / len(val_loader)\n    val_losses.append(avg_val_loss)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T21:37:04.072475Z","iopub.execute_input":"2025-08-12T21:37:04.073278Z","iopub.status.idle":"2025-08-12T21:39:26.813462Z","shell.execute_reply.started":"2025-08-12T21:37:04.073243Z","shell.execute_reply":"2025-08-12T21:39:26.812625Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plotting the losses","metadata":{}},{"cell_type":"code","source":"plt.plot(range(1, 16), train_losses, marker='o')\nplt.plot(range(1, 16), val_losses, marker='x')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss vs Epoch\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T21:39:40.109545Z","iopub.execute_input":"2025-08-12T21:39:40.110044Z","iopub.status.idle":"2025-08-12T21:39:40.309170Z","shell.execute_reply.started":"2025-08-12T21:39:40.110014Z","shell.execute_reply":"2025-08-12T21:39:40.308520Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# zooming in the graph","metadata":{}},{"cell_type":"code","source":"plt.plot(range(4, 16), train_losses[3:], marker='o')\nplt.plot(range(4, 16), val_losses[3:], marker='x')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss vs Epoch\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T21:41:19.541862Z","iopub.execute_input":"2025-08-12T21:41:19.542159Z","iopub.status.idle":"2025-08-12T21:41:19.731874Z","shell.execute_reply.started":"2025-08-12T21:41:19.542138Z","shell.execute_reply":"2025-08-12T21:41:19.731013Z"}},"outputs":[],"execution_count":null}]}